Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job           count    min threads    max threads
----------  -------  -------------  -------------
all               1              1              1
get_report        1              1              1
total             2              1              1

Select jobs to execute...

[Tue Aug 16 02:54:39 2022]
rule get_report:
    output: output/report.tsv
    jobid: 1
    reason: Missing output files: output/report.tsv; Set of input files has changed since last execution; Code has changed since last execution
    resources: tmpdir=/tmp

[Tue Aug 16 02:54:41 2022]
Error in rule get_report:
    jobid: 1
    output: output/report.tsv

RuleException:
CalledProcessErrorin line 46 of /home/jovyan/Documents/jupyter/pep-detective/workflow/Snakefile:
Command 'set -euo pipefail;  /opt/conda/bin/python3.10 /home/jovyan/Documents/jupyter/pep-detective/.snakemake/scripts/tmp68d1o2wg.get_report.py' returned non-zero exit status 1.
  File "/home/jovyan/Documents/jupyter/pep-detective/workflow/Snakefile", line 46, in __rule_get_report
  File "/opt/conda/lib/python3.10/concurrent/futures/thread.py", line 58, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2022-08-16T025439.061127.snakemake.log
